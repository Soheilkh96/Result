






.version 4.0
.target sm_20
.address_size 64

.const .align 4 .b8 d_OptionData[20480];
.global .align 4 .b8 d_CallValue[4096];
.global .align 4 .b8 d_CallBuffer[8454144];



.entry _Z21binomialOptionsKernelv(

)
{
.reg .pred %p<13>;
.reg .s32 %r<29>;
.reg .f32 %f<36>;
.reg .s64 %rd<28>;

	.shared .align 4 .b8 _Z21binomialOptionsKernelv$__cuda_local_var_59101_34_non_const_callA[1028];

	.shared .align 4 .b8 _Z21binomialOptionsKernelv$__cuda_local_var_59102_34_non_const_callB[1028];

mov.u32 %r1, %ctaid.x;
mul.wide.u32 %rd10, %r1, 20;
mov.u64 %rd11, d_OptionData;
add.s64 %rd1, %rd11, %rd10;
ld.const.f32 %f1, [%rd1+12];
ld.const.f32 %f2, [%rd1+16];
mov.u32 %r2, %tid.x;
setp.gt.s32	%p1, %r2, 2048;
@%p1 bra BB0_3;

ld.const.f32 %f3, [%rd1];
ld.const.f32 %f4, [%rd1+4];
ld.const.f32 %f5, [%rd1+8];
cvt.s64.s32	%rd12, %r2;
mul.lo.s32 %r15, %r1, 2064;
cvt.u64.u32	%rd13, %r15;
add.s64 %rd14, %rd12, %rd13;
shl.b64 %rd15, %rd14, 2;
mov.u64 %rd16, d_CallBuffer;
add.s64 %rd27, %rd16, %rd15;
mov.u32 %r25, %r2;

BB0_2:
mov.u32 %r3, %r25;
cvt.rn.f32.s32	%f8, %r3;
fma.rn.f32 %f9, %f8, 0f40000000, 0fC5000000;
mul.f32 %f10, %f5, %f9;
mul.f32 %f11, %f10, 0f3FB8AA3B;
cvt.rzi.f32.f32	%f12, %f11;
mov.f32 %f13, 0fBF317200;
fma.rn.f32 %f14, %f12, %f13, %f10;
mov.f32 %f15, 0fB5BFBE8E;
fma.rn.f32 %f16, %f12, %f15, %f14;
mul.f32 %f7, %f16, 0f3FB8AA3B;

	ex2.approx.ftz.f32 %f6,%f7;

	add.f32 %f17, %f12, 0f00000000;
ex2.approx.f32 %f18, %f17;
mul.f32 %f19, %f6, %f18;
setp.lt.f32	%p2, %f10, 0fC2D20000;
selp.f32	%f20, 0f00000000, %f19, %p2;
setp.gt.f32	%p3, %f10, 0f42D20000;
selp.f32	%f21, 0f7F800000, %f20, %p3;
mul.f32 %f22, %f3, %f21;
sub.f32 %f23, %f22, %f4;
setp.gt.f32	%p4, %f23, 0f00000000;
selp.f32	%f24, %f23, 0f00000000, %p4;
st.global.f32 [%rd27], %f24;
add.s64 %rd27, %rd27, 1024;
add.s32 %r4, %r3, 256;
setp.lt.s32	%p5, %r4, 2049;
mov.u32 %r25, %r4;
@%p5 bra BB0_2;

BB0_3:
mul.lo.s32 %r17, %r1, 2064;
cvt.u64.u32	%rd5, %r17;
mul.wide.s32 %rd17, %r2, 4;
mov.u64 %rd18, _Z21binomialOptionsKernelv$__cuda_local_var_59101_34_non_const_callA;
add.s64 %rd6, %rd18, %rd17;
mov.u64 %rd19, _Z21binomialOptionsKernelv$__cuda_local_var_59102_34_non_const_callB;
add.s64 %rd7, %rd19, %rd17;
mov.u32 %r26, 2048;

BB0_4:
setp.lt.s32	%p6, %r26, 1;
@%p6 bra BB0_13;

mov.u32 %r27, 0;

BB0_6:
sub.s32 %r19, %r26, %r27;
mov.u32 %r20, 255;
min.s32 %r7, %r20, %r19;
add.s32 %r8, %r7, -32;
bar.sync 0;
mov.u32 %r21, %tid.x;
setp.gt.s32	%p7, %r21, %r7;
add.s32 %r22, %r27, %r21;
cvt.s64.s32	%rd20, %r22;
add.s64 %rd21, %rd20, %rd5;
shl.b64 %rd22, %rd21, 2;
mov.u64 %rd23, d_CallBuffer;
add.s64 %rd8, %rd23, %rd22;
@%p7 bra BB0_8;

ld.global.f32 %f25, [%rd8];
st.shared.f32 [%rd6], %f25;

BB0_8:
add.s32 %r28, %r7, -1;

BB0_9:
bar.sync 0;
ld.shared.f32 %f26, [%rd6+4];
ld.shared.f32 %f27, [%rd6];
mul.f32 %f28, %f2, %f27;
fma.rn.f32 %f29, %f1, %f26, %f28;
st.shared.f32 [%rd7], %f29;
bar.sync 0;
ld.shared.f32 %f30, [%rd7+4];
ld.shared.f32 %f31, [%rd7];
mul.f32 %f32, %f2, %f31;
fma.rn.f32 %f33, %f1, %f30, %f32;
st.shared.f32 [%rd6], %f33;
add.s32 %r28, %r28, -2;
setp.ge.s32	%p8, %r28, %r8;
@%p8 bra BB0_9;

bar.sync 0;
setp.gt.s32	%p9, %r21, %r8;
@%p9 bra BB0_12;

ld.shared.f32 %f34, [%rd6];
st.global.f32 [%rd8], %f34;

BB0_12:
add.s32 %r27, %r27, 224;
setp.lt.s32	%p10, %r27, %r26;
@%p10 bra BB0_6;

BB0_13:
add.s32 %r26, %r26, -32;
setp.gt.s32	%p11, %r26, 0;
@%p11 bra BB0_4;

mov.u32 %r23, %tid.x;
setp.ne.s32	%p12, %r23, 0;
@%p12 bra BB0_16;

ld.shared.f32 %f35, [_Z21binomialOptionsKernelv$__cuda_local_var_59101_34_non_const_callA];
mul.wide.u32 %rd24, %r1, 4;
mov.u64 %rd25, d_CallValue;
add.s64 %rd26, %rd25, %rd24;
st.global.f32 [%rd26], %f35;

BB0_16:
ret;
}



